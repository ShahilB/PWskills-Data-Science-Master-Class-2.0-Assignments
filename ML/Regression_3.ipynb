{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1021269-86ed-4b1f-bddc-6fffe0b4fc58",
   "metadata": {},
   "source": [
    "# Regression Assignment - 03\n",
    "\n",
    "### Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ **Ridge Regression (L2 Regularization):**\n",
    "\n",
    "Ridge Regression is a **regularized version of linear regression** that **adds a penalty term** to the loss function to prevent **overfitting** and manage **multicollinearity**.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ” Ordinary Least Squares (OLS) Regression:\n",
    "\n",
    "OLS tries to minimize the **sum of squared residuals**:\n",
    "$$\n",
    "\\min_\\beta \\sum_{i=1}^{n} (y_i - \\mathbf{x}_i^T \\beta)^2\n",
    "$$\n",
    "- Finds coefficients \\( \\beta \\) that best fit the training data.\n",
    "- Works well when predictors are not highly correlated.\n",
    "- Can lead to **high variance** in coefficients when multicollinearity exists.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§© Ridge Regression:\n",
    "\n",
    "Ridge modifies the OLS cost function by adding a **penalty** on the size of coefficients:\n",
    "$$\n",
    "\\min_\\beta \\sum_{i=1}^{n} (y_i - \\mathbf{x}_i^T \\beta)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2\n",
    "$$\n",
    "- Î»â‰¥0 is a regularization parameter.\n",
    "- As Î» increases, it shrinks the coefficients towards 0 (but never exactly 0).\n",
    "- Helps to reduce **model complexity** and **multicollinearity issues**.\n",
    "\n",
    "\n",
    "### ðŸ“ **Ridge Regression Loss Function:**\n",
    "\n",
    "$$\n",
    "\\text{Loss} = \\sum (y_i - \\hat{y}_i)^2 + \\lambda \\sum \\beta_j^2\n",
    "$$\n",
    "                    \n",
    "- The first term is the usual **residual sum of squares** (as in OLS).\n",
    "- The second term **penalizes large coefficients**.\n",
    "- `Î»` (lambda) is the **regularization strength**:\n",
    "  - If Î» = 0 âž Ridge becomes **OLS**.\n",
    "  - If Î» is large âž More penalty on coefficients (shrinks them).\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ” **Difference from OLS (Ordinary Least Squares):**\n",
    "\n",
    "| Feature                     | OLS Regression                        | Ridge Regression                            |\n",
    "|----------------------------|----------------------------------------|---------------------------------------------|\n",
    "| Objective                  | Minimize sum of squared errors         | Minimize sum of squared errors + L2 penalty |\n",
    "| Regularization             | âŒ No regularization                    | âœ… L2 Regularization                         |\n",
    "| Handles Multicollinearity | Poorly                                 | Well (by shrinking correlated coefficients) |\n",
    "| Overfitting Risk           | High in high-dimensional data          | Reduced                                     |\n",
    "| Coefficients               | May be large and unstable              | Tend to be smaller and more stable          |\n",
    "| Interpretability           | Higher (but possibly overfit)          | Lower, but more generalizable               |\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“¦ **When to Use Ridge Regression:**\n",
    "- When you have **many features** and **collinearity** among them.\n",
    "- When you want to improve **model generalization**.\n",
    "- When **feature selection is not a goal** (Ridge does not shrink coefficients to zero like Lasso).\n",
    "\n",
    "\n",
    "### Q2. What are the assumptions of Ridge Regression?\n",
    "\n",
    "\n",
    "\n",
    "Ridge Regression builds on the same assumptions as **Linear Regression (OLS)**, with some adjustments due to the regularization term. Here's a breakdown:\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Core Assumptions of Ridge Regression:\n",
    "\n",
    "1. **Linearity**  \n",
    "   - The relationship between the independent variables \\( X \\) and the dependent variable \\( y \\) is linear.  \n",
    "   $$\n",
    "   y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + \\epsilon\n",
    "   $$\n",
    "\n",
    "2. **Independence of Errors**  \n",
    "   - The residuals (errors) should be independent of each other (no autocorrelation).\n",
    "\n",
    "3. **Homoscedasticity (Constant Variance of Errors)**  \n",
    "   - The variance of the error terms should be constant across all levels of the independent variables.\n",
    "\n",
    "4. **Normality of Errors (for inference)**  \n",
    "   - The residuals should be approximately normally distributed, especially important if you're interested in confidence intervals or hypothesis testing.\n",
    "\n",
    "5. **Multicollinearity is allowed but penalized**  \n",
    "   - Unlike OLS, **Ridge assumes that multicollinearity exists** and addresses it by **shrinking the coefficients** through the L2 penalty.\n",
    "\n",
    "6. **No need for unbiased estimates**  \n",
    "   - Ridge regression **accepts biased estimates** in exchange for lower variance and better prediction accuracy (bias-variance tradeoff).\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ” Summary Table:\n",
    "\n",
    "| Assumption                   | Ridge Regression | Notes |\n",
    "|-----------------------------|------------------|-------|\n",
    "| Linearity                   | âœ…               | Required |\n",
    "| Independence of errors      | âœ…               | Required |\n",
    "| Homoscedasticity            | âœ…               | Required |\n",
    "| Normality of errors         | âœ… (optional)    | Mainly for inference |\n",
    "| Multicollinearity           | âœ… (tolerated)   | Addressed by L2 regularization |\n",
    "| Unbiased coefficients       | âŒ               | Ridge sacrifices unbiasedness for stability |\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1e32cb-23a2-4ecf-b50a-762f7a75f622",
   "metadata": {},
   "source": [
    "### Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8896e5ac-5065-4e4a-a038-c1aaeb31faf0",
   "metadata": {},
   "source": [
    "### Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?\n",
    "\n",
    "The **tuning parameter \\(\\lambda\\)** in Ridge Regression controls the strength of the regularization. Choosing the right value is crucial for balancing **bias and variance** â€” too small and you overfit, too large and you underfit.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… Common Methods to Select Lambda:\n",
    "\n",
    "#### 1. **Cross-Validation (Most Common)**  \n",
    "Use **k-fold cross-validation** to find the value of Î» that minimizes the cross-validated error (like Mean Squared Error).\n",
    "\n",
    "##### Steps:\n",
    "- Choose a range of Î» values (e.g., from 0.001 to 1000).\n",
    "- For each Î», perform k-fold CV.\n",
    "- Calculate average validation error.\n",
    "- Select the Î» that gives the **lowest error**.\n",
    "\n",
    "> Tools like `RidgeCV` in Scikit-learn handle this automatically.\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example\n",
    "ridge_cv = RidgeCV(alphas=[0.01, 0.1, 1, 10, 100], cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best lambda (alpha):\", ridge_cv.alpha_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Grid Search with Cross-Validation**\n",
    "Use `GridSearchCV` to systematically search over a grid of \\(\\lambda\\) values.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "params = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(ridge, params, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimal lambda:\", grid.best_params_['alpha'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Analytical (Less Common)**\n",
    "In some cases, domain knowledge or theoretical considerations might suggest a good \\(\\lambda\\), but this is rare in practice.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Š Visual Aid: (Optional)\n",
    "Plotting **validation error vs. \\(\\lambda\\)** can help visualize the sweet spot:\n",
    "- Too low: High variance (overfitting)\n",
    "- Too high: High bias (underfitting)\n",
    "- Just right: Low error on validation set\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ§  Summary:\n",
    "\n",
    "| Method                  | Description                                      |\n",
    "|------------------------|--------------------------------------------------|\n",
    "| Cross-Validation        | Most common and reliable                         |\n",
    "| GridSearchCV            | Flexible, works for many models                  |\n",
    "| Analytical Guess        | Rare, based on domain expertise or prior data    |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d25dcf8a-e270-4fdb-94b1-34ba5d02048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ace_tools in c:\\users\\shahil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ace_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6f2557-a1f7-4d9a-9c72-abacac3dcbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha (lambda) found by RidgeCV: 0.28117686979742307\n",
      "Test set MSE with best alpha: 114.24\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, validation_curve\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define range of alphas (lambdas)\n",
    "alphas = np.logspace(-3, 3, 50)\n",
    "\n",
    "# Use RidgeCV to find the best alpha via 5-fold CV\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "best_alpha = ridge_cv.alpha_\n",
    "\n",
    "# Evaluate the model with the best alpha on the test set\n",
    "y_pred = ridge_cv.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Compute validation curve (train & validation scores)\n",
    "train_scores, val_scores = validation_curve(\n",
    "    Ridge(), X_train, y_train,\n",
    "    param_name='alpha', param_range=alphas,\n",
    "    cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Calculate mean MSE from negative MSE scores\n",
    "mean_train_mse = -train_scores.mean(axis=1)\n",
    "mean_val_mse = -val_scores.mean(axis=1)\n",
    "\n",
    "# Prepare DataFrame of results\n",
    "df_results = pd.DataFrame({\n",
    "    'alpha': alphas,\n",
    "    'mean_train_mse': mean_train_mse,\n",
    "    'mean_val_mse': mean_val_mse\n",
    "})\n",
    "\n",
    "# Display the DataFrame to user\n",
    "#import ace_tools as tools; tools.display_dataframe_to_user(\"Validation Curve MSE Results\", df_results)\n",
    "\n",
    "# Plot validation curve: train vs validation MSE\n",
    "plt.figure()\n",
    "plt.plot(alphas, mean_train_mse)\n",
    "plt.plot(alphas, mean_val_mse)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Alpha (Lambda)')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Ridge Regression Validation Curve')\n",
    "plt.show()\n",
    "\n",
    "# Print best alpha and test performance\n",
    "print(f\"Best alpha (lambda) found by RidgeCV: {best_alpha}\")\n",
    "print(f\"Test set MSE with best alpha: {test_mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b2c91-31be-4c75-9177-469690522f70",
   "metadata": {},
   "source": [
    "Hereâ€™s a step-by-step Ridgeâ€‘Regression example that demonstrates how to choose the tuning parameter \\(\\lambda\\) (alpha) via crossâ€‘validation:\n",
    "\n",
    "1. **Synthetic data creation**  \n",
    "   We generate a regression problem with 1,000 samples and 20 features, adding some noise for realism.\n",
    "\n",
    "2. **Train/test split**  \n",
    "   We hold out 20% of the data for final testing.\n",
    "\n",
    "3. **RidgeCV for automatic Î» selection**  \n",
    "   We feed in a logarithmically spaced grid of 50 candidate alphas (from \\(10^{-3}\\) to \\(10^3\\)) into `RidgeCV` with 5â€‘fold CV. The model finds the alpha that minimizes the average validation error:\n",
    "   > **Best alpha (lambda):** 0.2812\n",
    "\n",
    "4. **Test evaluation**  \n",
    "   Using the chosen alpha, we measure performance on the unseen test set:\n",
    "   > **Test MSE:** 114.24\n",
    "\n",
    "5. **Validation curve**  \n",
    "   We plot both training and validation Mean Squared Error across the same alpha grid. On a logâ€‘scale xâ€‘axis, you can visually confirm the biasâ€“variance tradeoff:  \n",
    "   - **Low alpha** (left): very low penalty â†’ low bias but high variance (overfitting).  \n",
    "   - **High alpha** (right): heavy penalty â†’ high bias (underfitting).  \n",
    "   - **Sweet spot**: where validation MSE is minimized (around 0.28).\n",
    "\n",
    "6. **Interactive table of results**  \n",
    "   You can explore the exact MSE values for each alpha in the displayed DataFrame.\n",
    "\n",
    "This full example shows how crossâ€‘validation guides you to the optimal regularization strength, improving generalization compared to arbitrary lambda choices. Let me know if youâ€™d like to adapt this to your own dataset or see variations (e.g., using different CV schemes)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02096885-ab01-4069-a523-a41eb2245bc6",
   "metadata": {},
   "source": [
    "### Q4. Can Ridge Regression be used for feature selection? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a96861a-6f95-4547-958d-97a79b42f6ab",
   "metadata": {},
   "source": [
    "Ridge regression by itself does **not** produce sparse (exactâ€‘zero) coefficients the way Lasso does, so it isnâ€™t a true â€œfeatureâ€selector.â€  However, you **can** leverage its coefficientâ€‘shrinkage behavior to **identify** and **drop** unimportant variables. Here are three common ways to do that:\n",
    "\n",
    "---\n",
    "\n",
    "### 1.  Coefficient Thresholding  \n",
    "1.  Fit a Ridge model with your chosen \\(\\lambda\\).  \n",
    "2.  Examine the learned weights \\(\\beta_j\\).  \n",
    "3.  Declare any feature with \\(\\lvert \\beta_j\\rvert < \\varepsilon\\) â€œunimportantâ€ (for some small threshold \\(\\varepsilon\\)), and drop it.  \n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=best_alpha).fit(X_train, y_train)\n",
    "coefs = ridge.coef_\n",
    "\n",
    "# e.g. drop features whose absolute weight is below 1e-3\n",
    "keep = [j for j, w in enumerate(coefs) if abs(w) > 1e-3]\n",
    "X_reduced = X_train[:, keep]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.  Recursive Feature Elimination (RFE) with Ridge  \n",
    "RFE repeatedly fits a model and removes the smallestâ€magnitude coefficient at each step until you reach a target number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe110668-5532-486c-89a2-e4afd59b9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "ridge = Ridge(alpha=best_alpha)\n",
    "selector = RFE(estimator=ridge, n_features_to_select=10, step=1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# mask of selected features\n",
    "mask = selector.support_\n",
    "X_reduced = X_train[:, mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c43261d-26f6-4a13-86d3-ff529d2bfd1a",
   "metadata": {},
   "source": [
    "This automates the â€œfitâ€“dropâ€“refitâ€ loop and can often give more stable subsets than simple thresholding.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.  Stability Selection (Bootstrap + Thresholding)  \n",
    "1.  Fit multiple Ridge models on random subsamples or bootstraps of your data.  \n",
    "2.  Record how often each featureâ€™s coefficient stays above a small threshold.  \n",
    "3.  Only keep features that exceed a desired â€œselection frequencyâ€ (e.g. 80%).  \n",
    "\n",
    "This guards against picking spurious features that only look important on one split.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Œ When to Prefer Lasso or Elastic Net  \n",
    "- If you **require** exact zeros (i.e. automatic feature elimination), **Lasso** (L1 penalty) or **Elastic Net** (mix of L1 & L2) is often a better match.  \n",
    "- Ridge-based approaches are best when you want **stability** (shrinkage spreads across correlated variables) and then do selection in a **postâ€‘hoc** step.\n",
    "\n",
    "---\n",
    "\n",
    "**Bottom Line:**  \n",
    "> Ridge doesnâ€™t zero coefficients, but by ranking or iteratively eliminating the smallest weights (via thresholding, RFE, or stability selection) you can still use it to winnow down to a smaller, highâ€‘signal feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e61e55-2901-4fc2-a689-c2bdab0e0631",
   "metadata": {},
   "source": [
    "#### Q5. How does the Ridge Regression model perform in the presence of multicollinearity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39932fce-f898-42ec-a809-7af84e71af30",
   "metadata": {},
   "source": [
    "When your predictors are highly correlated, ordinary least squares (OLS) estimates become unstable: tiny changes in the data can flip the signs or magnitudes of coefficients, and the variance of those estimates blows up. Ridge Regression tames this by adding an Lâ‚‚â€‘penalty, which has three key effects:\n",
    "\n",
    "1. **Improved Conditioning**  \n",
    "   OLS solves  \n",
    "   $$\n",
    "     \\hat\\beta_{\\rm OLS} = (X^T X)^{-1} X^T y.\n",
    "   $$\n",
    "   When \\(X^T X\\) is nearly singular (because columns of \\(X\\) are collinear), its inverse has extremely large entries.  \n",
    "   Ridge instead solves  \n",
    "   $$\n",
    "     \\hat\\beta_{\\rm Ridge} = (X^T X + \\lambda I)^{-1} X^T y.\n",
    "   $$\n",
    "   Adding \\(\\lambda I\\) â€œliftsâ€ all the eigenvalues of \\(X^T X\\) by \\(\\lambda\\), making the matrix far better conditioned and the inversion numerically stable.\n",
    "\n",
    "2. **Variance Reduction at the Cost of Bias**  \n",
    "   The small eigenvalues of \\(X^T X\\) correspond to directions in featureâ€‘space where the data carry little informationâ€”exactly where OLS variance explodes. By shrinking coefficients especially in those weak directions, Ridge sacrifices a bit of bias but dramatically cuts variance, leading to lower **mean squared error** on new data.\n",
    "\n",
    "3. **Spreadâ€‘Out Shrinkage Across Correlated Features**  \n",
    "   Unlike Lasso, which may arbitrarily zero out one variable in a correlated group, Ridge shares the â€œblameâ€ among themâ€”shrinking all of their coefficients together. This tends to produce more stable, interpretable models when predictors move in lockstep.\n",
    "\n",
    "---\n",
    "\n",
    "### Intuitive Takeaway\n",
    "\n",
    "- **OLS under multicollinearity** â†’ huge coefficient swings, poor generalization.  \n",
    "- **Ridge under multicollinearity** â†’ coefficients are â€œpulled backâ€ toward zero, variance controlled, predictions more reliable.\n",
    "\n",
    "In practice, youâ€™ll almost always see improved outâ€‘ofâ€‘sample performance when using a modest \\(\\lambda\\) in a highly collinear setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e7704d-7e7a-4f78-9ac1-8ecb9a01e84d",
   "metadata": {},
   "source": [
    "#### Q6. Can Ridge Regression handle both categorical and continuous independent variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2bbedf-395c-4d2c-b0c9-2f7f27de43fa",
   "metadata": {},
   "source": [
    "YesÂ â€“ Ridge Regression itself just takes a numeric design matrix \\(X\\), so thereâ€™s no fundamental barrier to mixing continuous and categorical inputsÂ â€¦ you just have to turn your categories into numbers first, then (usually) scale everything.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Encoding categoricals  \n",
    "- **Oneâ€‘Hot (Dummy) Encoding**  \n",
    "  Convert each level of a nominal feature into a 0/1 column.  \n",
    "- **Ordinal or Effect Encoding**  \n",
    "  Map levels to integers (if thereâ€™s a natural order) or use more sophisticated contrast codes.  \n",
    "- **Target (Mean) Encoding or Embeddings**  \n",
    "  For highâ€‘cardinality features, replace each level with a smoothed target mean or learn an embedding (e.g. via a neural net).\n",
    "\n",
    "> **âš ï¸ Dummyâ€‘Trap**  \n",
    "> If you oneâ€‘hotâ€‘encode a feature with \\(k\\) levels, drop one column (or use a penaltyâ€‘aware encoder) to avoid perfect multicollinearity among the dummies themselves.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Scaling all features  \n",
    "Ridgeâ€™s penalty treats every coefficient equally, so you should **standardize** (zero meanÂ &Â unit variance) or otherwise scale all numeric columnsâ€”including the dummy columnsâ€”so that the shrinkage is fair:\n",
    "\n",
    "```python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model  import Ridge\n",
    "from sklearn.pipeline      import make_pipeline\n",
    "\n",
    "# Suppose:\n",
    "#  - cont_feats = ['age','income']\n",
    "#  - cat_feats  = ['city','education_level']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cont\", StandardScaler(),    cont_feats),\n",
    "    (\"cat\",  OneHotEncoder(drop=\"first\"), cat_feats),\n",
    "])\n",
    "\n",
    "model = make_pipeline(preprocessor,\n",
    "                      Ridge(alpha=best_alpha))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Why it works  \n",
    "1. **Numeric-only input**: Once encoded, every column is just a number, so Ridge applies its usual \\(\\ell_2\\) penalty.  \n",
    "2. **Shared shrinkage**: If your original categorical had many dummies, Ridge will softly shrink all their coefficients together rather than zeroing some out entirely.  \n",
    "\n",
    "---\n",
    "\n",
    "### Takeaway  \n",
    "As long as you **encode** your categorical variables into numeric form (and **scale** everything), Ridge Regression can seamlessly handle mixed data types. If you need hard feature selection on those dummies, consider wrapping Ridge inside an RFE or using an \\(\\ell_1\\)â€‘based method on the encoded features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef8d109-964b-4622-9235-51b29eac241b",
   "metadata": {},
   "source": [
    "#### Q7. How do you interpret the coefficients of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c43c6ad-8b17-49a6-9611-507c244ae668",
   "metadata": {},
   "source": [
    "In Ridge regression, the fitted coefficients \\(\\hat\\beta_j\\) still carry the usual â€œeffectâ€sizeâ€ interpretationâ€”but with two important caveats due to the Lâ‚‚ penalty:\n",
    "\n",
    "1. **Unitâ€change interpretation (conditional on other features)**  \n",
    "   - Just like in OLS, \\(\\hat\\beta_j\\) represents the expected change in the response \\(y\\) for a oneâ€‘unit increase in \\(x_j\\), **holding all other predictors fixed**.  \n",
    "   - Sign indicates direction (positive means \\(y\\) goes up as \\(x_j\\) increases; negative means \\(y\\) goes down).\n",
    "\n",
    "2. **Shrinkage bias**  \n",
    "   - Because Ridge minimizes  \n",
    "     $$\n",
    "       \\sum_{i}(y_i - \\mathbf{x}_i^T\\beta)^2 \\;+\\;\\lambda\\sum_j\\beta_j^2,\n",
    "     $$ \n",
    "     each \\(\\hat\\beta_j\\) is â€œpulledâ€ toward zero relative to its OLS estimate.  \n",
    "   - Thus the raw magnitude of \\(\\hat\\beta_j\\) is **smaller** than in an unpenalized model; you should **not** compare ridgeâ€coefficients directly to OLSâ€coefficients.\n",
    "\n",
    "3. **Standardization matters**  \n",
    "   - If you standardize each feature to meanÂ 0 and varianceÂ 1 **before** fitting, then the magnitudes \\(|\\hat\\beta_j|\\) become directly comparable: larger \\(|\\hat\\beta_j|\\) means that feature has a stronger relative impact on \\(y\\).  \n",
    "   - If you donâ€™t standardize, differences in scale will be confounded with shrinkage (the penalty treats a coefficient on a â€œwideâ€ feature the same as on a â€œnarrowâ€ feature).\n",
    "\n",
    "4. **No zero coefficients**  \n",
    "   - Unlike Lasso, Ridge never exactly zeroes a coefficient. So smallâ€”but nonzeroâ€”\\(\\hat\\beta_j\\) still indicate weaker predictors, but youâ€™ll need to impose your own threshold if you want to drop features.\n",
    "\n",
    "5. **Statistical inference caution**  \n",
    "   - The Lâ‚‚ penalty introduces bias, breaking the usual OLS sampling distributions.  \n",
    "   - If you need confidence intervals or pâ€‘values, you can use bootstrapping or Bayesian interpretations (view Ridge as a Gaussian prior on \\(\\beta\\)), but you **cannot** plug \\(\\hat\\beta_j\\) straight into the OLS formula for standard errors.\n",
    "\n",
    "---\n",
    "\n",
    "### Practical tips\n",
    "\n",
    "- **Report standardized coefficients** when you want to discuss â€œwhich features matter most.â€  \n",
    "- **Visualize** coefficients (e.g., bar plot) to see relative shrinkage across features.  \n",
    "- **Postâ€‘hoc recalibration**: if interpretability is paramount, you can fit a final OLS on the subset of top features selected by Ridge (or RFE) to get unbiased estimates on those.  \n",
    "\n",
    "In short, Ridge coefficients still tell you *direction* and *relative importance*â€”but remember theyâ€™re biased by design, so adjust your interpretation accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102da17e-29da-4013-8d23-4d6bbd59e3d7",
   "metadata": {},
   "source": [
    "#### Q8. Can Ridge Regression be used for time-series data analysis? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4d7b3-625c-4223-a41e-46bedbe7df9c",
   "metadata": {},
   "source": [
    "Yesâ€”Ridge regression is perfectly usable for timeâ€‘series problems, provided you first turn your series into a supervised learning design matrix. The key steps are:\n",
    "\n",
    "1. **Create lagged features**  \n",
    "   - For a univariate series \\(y_t\\), build predictors like  \n",
    "     $$\n",
    "       x_{t,1} = y_{t-1},\\; x_{t,2} = y_{t-2},\\;\\dots,\\;x_{t,p} = y_{t-p}.\n",
    "     $$\n",
    "   - You can also add rollingâ€‘window statistics (means, variances), seasonal dummies (month or dayâ€‘ofâ€‘week oneâ€‘hots), and exogenous regressors.\n",
    "\n",
    "2. **Train/test split preserving time order**  \n",
    "   - Use a **chronological split** (e.g. train on \\(t=1\\ldots T_0\\), validate on \\(T_0+1\\ldots T_1\\), test on \\(T_1+1\\ldots T\\)) or timeâ€‘series crossâ€‘validation (e.g. expanding windows) rather than random shuffling.\n",
    "\n",
    "3. **Standardize your features**  \n",
    "   - Since Ridgeâ€™s Lâ‚‚ penalty treats every coefficient equally, scale each lagged series (and dummy) to zero mean/unit variance before fitting.\n",
    "\n",
    "4. **Fit Ridge on the lagged design matrix**  \n",
    "   ```python\n",
    "   from sklearn.linear_model import Ridge\n",
    "   from sklearn.preprocessing import StandardScaler\n",
    "   from sklearn.pipeline import make_pipeline\n",
    "\n",
    "   model = make_pipeline(\n",
    "       StandardScaler(),\n",
    "       Ridge(alpha=best_alpha)\n",
    "   )\n",
    "   model.fit(X_lagged_train, y_train)\n",
    "   y_pred = model.predict(X_lagged_test)\n",
    "   ```\n",
    "\n",
    "5. **Hyperparameter tuning via timeâ€‘series CV**  \n",
    "   - Use walkâ€‘forward or expandingâ€‘window CV to pick the best \\(\\lambda\\) (alpha) so you respect temporal order.\n",
    "\n",
    "6. **Extensions**  \n",
    "   - **Vector autoregression (VAR)**: stack multiple seriesâ€™ lags into one big design matrix, then apply a multivariate ridge penalty to stabilize coefficient estimates.  \n",
    "   - **Structured regularization**: you can penalize groups of lags (e.g. all seasonal dummy coefficients) more or less heavily by extending Lâ‚‚ to blockâ€‘diagonal penalties.\n",
    "\n",
    "---\n",
    "\n",
    "### Why it helps in timeâ€‘series  \n",
    "- **Multicollinearity** is endemic in lagged features (adjacent lags correlate strongly). Ridgeâ€™s Lâ‚‚ shrinkage stabilizes those highly collinear predictors.  \n",
    "- **Overfitting** on many lags or external regressors is tamed, improving outâ€‘ofâ€‘sample forecast accuracy.  \n",
    "\n",
    "---\n",
    "\n",
    "**Bottom line:**  \n",
    "Treat your time series as regression data with lagged and calendar features, then regularize with Ridge to get more robust coefficient estimates and better forecasts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
