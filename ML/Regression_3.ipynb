{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1021269-86ed-4b1f-bddc-6fffe0b4fc58",
   "metadata": {},
   "source": [
    "# Regression Assignment - 03\n",
    "\n",
    "### Q1. What is Ridge Regression, and how does it differ from ordinary least squares regression?\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 **Ridge Regression (L2 Regularization):**\n",
    "\n",
    "Ridge Regression is a **regularized version of linear regression** that **adds a penalty term** to the loss function to prevent **overfitting** and manage **multicollinearity**.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 Ordinary Least Squares (OLS) Regression:\n",
    "\n",
    "OLS tries to minimize the **sum of squared residuals**:\n",
    "$$\n",
    "\\min_\\beta \\sum_{i=1}^{n} (y_i - \\mathbf{x}_i^T \\beta)^2\n",
    "$$\n",
    "- Finds coefficients \\( \\beta \\) that best fit the training data.\n",
    "- Works well when predictors are not highly correlated.\n",
    "- Can lead to **high variance** in coefficients when multicollinearity exists.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧩 Ridge Regression:\n",
    "\n",
    "Ridge modifies the OLS cost function by adding a **penalty** on the size of coefficients:\n",
    "$$\n",
    "\\min_\\beta \\sum_{i=1}^{n} (y_i - \\mathbf{x}_i^T \\beta)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2\n",
    "$$\n",
    "- λ≥0 is a regularization parameter.\n",
    "- As λ increases, it shrinks the coefficients towards 0 (but never exactly 0).\n",
    "- Helps to reduce **model complexity** and **multicollinearity issues**.\n",
    "\n",
    "\n",
    "### 📐 **Ridge Regression Loss Function:**\n",
    "\n",
    "$$\n",
    "\\text{Loss} = \\sum (y_i - \\hat{y}_i)^2 + \\lambda \\sum \\beta_j^2\n",
    "$$\n",
    "                    \n",
    "- The first term is the usual **residual sum of squares** (as in OLS).\n",
    "- The second term **penalizes large coefficients**.\n",
    "- `λ` (lambda) is the **regularization strength**:\n",
    "  - If λ = 0 ➝ Ridge becomes **OLS**.\n",
    "  - If λ is large ➝ More penalty on coefficients (shrinks them).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 **Difference from OLS (Ordinary Least Squares):**\n",
    "\n",
    "| Feature                     | OLS Regression                        | Ridge Regression                            |\n",
    "|----------------------------|----------------------------------------|---------------------------------------------|\n",
    "| Objective                  | Minimize sum of squared errors         | Minimize sum of squared errors + L2 penalty |\n",
    "| Regularization             | ❌ No regularization                    | ✅ L2 Regularization                         |\n",
    "| Handles Multicollinearity | Poorly                                 | Well (by shrinking correlated coefficients) |\n",
    "| Overfitting Risk           | High in high-dimensional data          | Reduced                                     |\n",
    "| Coefficients               | May be large and unstable              | Tend to be smaller and more stable          |\n",
    "| Interpretability           | Higher (but possibly overfit)          | Lower, but more generalizable               |\n",
    "\n",
    "---\n",
    "\n",
    "### 📦 **When to Use Ridge Regression:**\n",
    "- When you have **many features** and **collinearity** among them.\n",
    "- When you want to improve **model generalization**.\n",
    "- When **feature selection is not a goal** (Ridge does not shrink coefficients to zero like Lasso).\n",
    "\n",
    "\n",
    "### Q2. What are the assumptions of Ridge Regression?\n",
    "\n",
    "\n",
    "\n",
    "Ridge Regression builds on the same assumptions as **Linear Regression (OLS)**, with some adjustments due to the regularization term. Here's a breakdown:\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Core Assumptions of Ridge Regression:\n",
    "\n",
    "1. **Linearity**  \n",
    "   - The relationship between the independent variables \\( X \\) and the dependent variable \\( y \\) is linear.  \n",
    "   $$\n",
    "   y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\dots + \\beta_p x_p + \\epsilon\n",
    "   $$\n",
    "\n",
    "2. **Independence of Errors**  \n",
    "   - The residuals (errors) should be independent of each other (no autocorrelation).\n",
    "\n",
    "3. **Homoscedasticity (Constant Variance of Errors)**  \n",
    "   - The variance of the error terms should be constant across all levels of the independent variables.\n",
    "\n",
    "4. **Normality of Errors (for inference)**  \n",
    "   - The residuals should be approximately normally distributed, especially important if you're interested in confidence intervals or hypothesis testing.\n",
    "\n",
    "5. **Multicollinearity is allowed but penalized**  \n",
    "   - Unlike OLS, **Ridge assumes that multicollinearity exists** and addresses it by **shrinking the coefficients** through the L2 penalty.\n",
    "\n",
    "6. **No need for unbiased estimates**  \n",
    "   - Ridge regression **accepts biased estimates** in exchange for lower variance and better prediction accuracy (bias-variance tradeoff).\n",
    "\n",
    "---\n",
    "\n",
    "### 🔁 Summary Table:\n",
    "\n",
    "| Assumption                   | Ridge Regression | Notes |\n",
    "|-----------------------------|------------------|-------|\n",
    "| Linearity                   | ✅               | Required |\n",
    "| Independence of errors      | ✅               | Required |\n",
    "| Homoscedasticity            | ✅               | Required |\n",
    "| Normality of errors         | ✅ (optional)    | Mainly for inference |\n",
    "| Multicollinearity           | ✅ (tolerated)   | Addressed by L2 regularization |\n",
    "| Unbiased coefficients       | ❌               | Ridge sacrifices unbiasedness for stability |\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1e32cb-23a2-4ecf-b50a-762f7a75f622",
   "metadata": {},
   "source": [
    "### Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8896e5ac-5065-4e4a-a038-c1aaeb31faf0",
   "metadata": {},
   "source": [
    "### Q3. How do you select the value of the tuning parameter (lambda) in Ridge Regression?\n",
    "\n",
    "The **tuning parameter \\(\\lambda\\)** in Ridge Regression controls the strength of the regularization. Choosing the right value is crucial for balancing **bias and variance** — too small and you overfit, too large and you underfit.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ Common Methods to Select Lambda:\n",
    "\n",
    "#### 1. **Cross-Validation (Most Common)**  \n",
    "Use **k-fold cross-validation** to find the value of λ that minimizes the cross-validated error (like Mean Squared Error).\n",
    "\n",
    "##### Steps:\n",
    "- Choose a range of λ values (e.g., from 0.001 to 1000).\n",
    "- For each λ, perform k-fold CV.\n",
    "- Calculate average validation error.\n",
    "- Select the λ that gives the **lowest error**.\n",
    "\n",
    "> Tools like `RidgeCV` in Scikit-learn handle this automatically.\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example\n",
    "ridge_cv = RidgeCV(alphas=[0.01, 0.1, 1, 10, 100], cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best lambda (alpha):\", ridge_cv.alpha_)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Grid Search with Cross-Validation**\n",
    "Use `GridSearchCV` to systematically search over a grid of \\(\\lambda\\) values.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge()\n",
    "params = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "grid = GridSearchCV(ridge, params, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimal lambda:\", grid.best_params_['alpha'])\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Analytical (Less Common)**\n",
    "In some cases, domain knowledge or theoretical considerations might suggest a good \\(\\lambda\\), but this is rare in practice.\n",
    "\n",
    "---\n",
    "\n",
    "### 📊 Visual Aid: (Optional)\n",
    "Plotting **validation error vs. \\(\\lambda\\)** can help visualize the sweet spot:\n",
    "- Too low: High variance (overfitting)\n",
    "- Too high: High bias (underfitting)\n",
    "- Just right: Low error on validation set\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 Summary:\n",
    "\n",
    "| Method                  | Description                                      |\n",
    "|------------------------|--------------------------------------------------|\n",
    "| Cross-Validation        | Most common and reliable                         |\n",
    "| GridSearchCV            | Flexible, works for many models                  |\n",
    "| Analytical Guess        | Rare, based on domain expertise or prior data    |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d25dcf8a-e270-4fdb-94b1-34ba5d02048f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ace_tools in c:\\users\\shahil\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install ace_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6f2557-a1f7-4d9a-9c72-abacac3dcbb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha (lambda) found by RidgeCV: 0.28117686979742307\n",
      "Test set MSE with best alpha: 114.24\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split, validation_curve\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=10, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define range of alphas (lambdas)\n",
    "alphas = np.logspace(-3, 3, 50)\n",
    "\n",
    "# Use RidgeCV to find the best alpha via 5-fold CV\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "best_alpha = ridge_cv.alpha_\n",
    "\n",
    "# Evaluate the model with the best alpha on the test set\n",
    "y_pred = ridge_cv.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Compute validation curve (train & validation scores)\n",
    "train_scores, val_scores = validation_curve(\n",
    "    Ridge(), X_train, y_train,\n",
    "    param_name='alpha', param_range=alphas,\n",
    "    cv=5, scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Calculate mean MSE from negative MSE scores\n",
    "mean_train_mse = -train_scores.mean(axis=1)\n",
    "mean_val_mse = -val_scores.mean(axis=1)\n",
    "\n",
    "# Prepare DataFrame of results\n",
    "df_results = pd.DataFrame({\n",
    "    'alpha': alphas,\n",
    "    'mean_train_mse': mean_train_mse,\n",
    "    'mean_val_mse': mean_val_mse\n",
    "})\n",
    "\n",
    "# Display the DataFrame to user\n",
    "#import ace_tools as tools; tools.display_dataframe_to_user(\"Validation Curve MSE Results\", df_results)\n",
    "\n",
    "# Plot validation curve: train vs validation MSE\n",
    "plt.figure()\n",
    "plt.plot(alphas, mean_train_mse)\n",
    "plt.plot(alphas, mean_val_mse)\n",
    "plt.xscale('log')\n",
    "plt.xlabel('Alpha (Lambda)')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Ridge Regression Validation Curve')\n",
    "plt.show()\n",
    "\n",
    "# Print best alpha and test performance\n",
    "print(f\"Best alpha (lambda) found by RidgeCV: {best_alpha}\")\n",
    "print(f\"Test set MSE with best alpha: {test_mse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b2c91-31be-4c75-9177-469690522f70",
   "metadata": {},
   "source": [
    "Here’s a step-by-step Ridge‑Regression example that demonstrates how to choose the tuning parameter \\(\\lambda\\) (alpha) via cross‑validation:\n",
    "\n",
    "1. **Synthetic data creation**  \n",
    "   We generate a regression problem with 1,000 samples and 20 features, adding some noise for realism.\n",
    "\n",
    "2. **Train/test split**  \n",
    "   We hold out 20% of the data for final testing.\n",
    "\n",
    "3. **RidgeCV for automatic λ selection**  \n",
    "   We feed in a logarithmically spaced grid of 50 candidate alphas (from \\(10^{-3}\\) to \\(10^3\\)) into `RidgeCV` with 5‑fold CV. The model finds the alpha that minimizes the average validation error:\n",
    "   > **Best alpha (lambda):** 0.2812\n",
    "\n",
    "4. **Test evaluation**  \n",
    "   Using the chosen alpha, we measure performance on the unseen test set:\n",
    "   > **Test MSE:** 114.24\n",
    "\n",
    "5. **Validation curve**  \n",
    "   We plot both training and validation Mean Squared Error across the same alpha grid. On a log‑scale x‑axis, you can visually confirm the bias–variance tradeoff:  \n",
    "   - **Low alpha** (left): very low penalty → low bias but high variance (overfitting).  \n",
    "   - **High alpha** (right): heavy penalty → high bias (underfitting).  \n",
    "   - **Sweet spot**: where validation MSE is minimized (around 0.28).\n",
    "\n",
    "6. **Interactive table of results**  \n",
    "   You can explore the exact MSE values for each alpha in the displayed DataFrame.\n",
    "\n",
    "This full example shows how cross‑validation guides you to the optimal regularization strength, improving generalization compared to arbitrary lambda choices. Let me know if you’d like to adapt this to your own dataset or see variations (e.g., using different CV schemes)!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02096885-ab01-4069-a523-a41eb2245bc6",
   "metadata": {},
   "source": [
    "### Q4. Can Ridge Regression be used for feature selection? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a96861a-6f95-4547-958d-97a79b42f6ab",
   "metadata": {},
   "source": [
    "Ridge regression by itself does **not** produce sparse (exact‑zero) coefficients the way Lasso does, so it isn’t a true “feature‐selector.”  However, you **can** leverage its coefficient‑shrinkage behavior to **identify** and **drop** unimportant variables. Here are three common ways to do that:\n",
    "\n",
    "---\n",
    "\n",
    "### 1.  Coefficient Thresholding  \n",
    "1.  Fit a Ridge model with your chosen \\(\\lambda\\).  \n",
    "2.  Examine the learned weights \\(\\beta_j\\).  \n",
    "3.  Declare any feature with \\(\\lvert \\beta_j\\rvert < \\varepsilon\\) “unimportant” (for some small threshold \\(\\varepsilon\\)), and drop it.  \n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge = Ridge(alpha=best_alpha).fit(X_train, y_train)\n",
    "coefs = ridge.coef_\n",
    "\n",
    "# e.g. drop features whose absolute weight is below 1e-3\n",
    "keep = [j for j, w in enumerate(coefs) if abs(w) > 1e-3]\n",
    "X_reduced = X_train[:, keep]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2.  Recursive Feature Elimination (RFE) with Ridge  \n",
    "RFE repeatedly fits a model and removes the smallest‐magnitude coefficient at each step until you reach a target number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe110668-5532-486c-89a2-e4afd59b9657",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "ridge = Ridge(alpha=best_alpha)\n",
    "selector = RFE(estimator=ridge, n_features_to_select=10, step=1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "\n",
    "# mask of selected features\n",
    "mask = selector.support_\n",
    "X_reduced = X_train[:, mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c43261d-26f6-4a13-86d3-ff529d2bfd1a",
   "metadata": {},
   "source": [
    "This automates the “fit–drop–refit” loop and can often give more stable subsets than simple thresholding.\n",
    "\n",
    "---\n",
    "\n",
    "### 3.  Stability Selection (Bootstrap + Thresholding)  \n",
    "1.  Fit multiple Ridge models on random subsamples or bootstraps of your data.  \n",
    "2.  Record how often each feature’s coefficient stays above a small threshold.  \n",
    "3.  Only keep features that exceed a desired “selection frequency” (e.g. 80%).  \n",
    "\n",
    "This guards against picking spurious features that only look important on one split.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 When to Prefer Lasso or Elastic Net  \n",
    "- If you **require** exact zeros (i.e. automatic feature elimination), **Lasso** (L1 penalty) or **Elastic Net** (mix of L1 & L2) is often a better match.  \n",
    "- Ridge-based approaches are best when you want **stability** (shrinkage spreads across correlated variables) and then do selection in a **post‑hoc** step.\n",
    "\n",
    "---\n",
    "\n",
    "**Bottom Line:**  \n",
    "> Ridge doesn’t zero coefficients, but by ranking or iteratively eliminating the smallest weights (via thresholding, RFE, or stability selection) you can still use it to winnow down to a smaller, high‑signal feature set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e61e55-2901-4fc2-a689-c2bdab0e0631",
   "metadata": {},
   "source": [
    "#### Q5. How does the Ridge Regression model perform in the presence of multicollinearity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39932fce-f898-42ec-a809-7af84e71af30",
   "metadata": {},
   "source": [
    "When your predictors are highly correlated, ordinary least squares (OLS) estimates become unstable: tiny changes in the data can flip the signs or magnitudes of coefficients, and the variance of those estimates blows up. Ridge Regression tames this by adding an L₂‑penalty, which has three key effects:\n",
    "\n",
    "1. **Improved Conditioning**  \n",
    "   OLS solves  \n",
    "   $$\n",
    "     \\hat\\beta_{\\rm OLS} = (X^T X)^{-1} X^T y.\n",
    "   $$\n",
    "   When \\(X^T X\\) is nearly singular (because columns of \\(X\\) are collinear), its inverse has extremely large entries.  \n",
    "   Ridge instead solves  \n",
    "   $$\n",
    "     \\hat\\beta_{\\rm Ridge} = (X^T X + \\lambda I)^{-1} X^T y.\n",
    "   $$\n",
    "   Adding \\(\\lambda I\\) “lifts” all the eigenvalues of \\(X^T X\\) by \\(\\lambda\\), making the matrix far better conditioned and the inversion numerically stable.\n",
    "\n",
    "2. **Variance Reduction at the Cost of Bias**  \n",
    "   The small eigenvalues of \\(X^T X\\) correspond to directions in feature‑space where the data carry little information—exactly where OLS variance explodes. By shrinking coefficients especially in those weak directions, Ridge sacrifices a bit of bias but dramatically cuts variance, leading to lower **mean squared error** on new data.\n",
    "\n",
    "3. **Spread‑Out Shrinkage Across Correlated Features**  \n",
    "   Unlike Lasso, which may arbitrarily zero out one variable in a correlated group, Ridge shares the “blame” among them—shrinking all of their coefficients together. This tends to produce more stable, interpretable models when predictors move in lockstep.\n",
    "\n",
    "---\n",
    "\n",
    "### Intuitive Takeaway\n",
    "\n",
    "- **OLS under multicollinearity** → huge coefficient swings, poor generalization.  \n",
    "- **Ridge under multicollinearity** → coefficients are “pulled back” toward zero, variance controlled, predictions more reliable.\n",
    "\n",
    "In practice, you’ll almost always see improved out‑of‑sample performance when using a modest \\(\\lambda\\) in a highly collinear setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e7704d-7e7a-4f78-9ac1-8ecb9a01e84d",
   "metadata": {},
   "source": [
    "#### Q6. Can Ridge Regression handle both categorical and continuous independent variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2bbedf-395c-4d2c-b0c9-2f7f27de43fa",
   "metadata": {},
   "source": [
    "Yes – Ridge Regression itself just takes a numeric design matrix \\(X\\), so there’s no fundamental barrier to mixing continuous and categorical inputs … you just have to turn your categories into numbers first, then (usually) scale everything.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Encoding categoricals  \n",
    "- **One‑Hot (Dummy) Encoding**  \n",
    "  Convert each level of a nominal feature into a 0/1 column.  \n",
    "- **Ordinal or Effect Encoding**  \n",
    "  Map levels to integers (if there’s a natural order) or use more sophisticated contrast codes.  \n",
    "- **Target (Mean) Encoding or Embeddings**  \n",
    "  For high‑cardinality features, replace each level with a smoothed target mean or learn an embedding (e.g. via a neural net).\n",
    "\n",
    "> **⚠️ Dummy‑Trap**  \n",
    "> If you one‑hot‑encode a feature with \\(k\\) levels, drop one column (or use a penalty‑aware encoder) to avoid perfect multicollinearity among the dummies themselves.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Scaling all features  \n",
    "Ridge’s penalty treats every coefficient equally, so you should **standardize** (zero mean & unit variance) or otherwise scale all numeric columns—including the dummy columns—so that the shrinkage is fair:\n",
    "\n",
    "```python\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model  import Ridge\n",
    "from sklearn.pipeline      import make_pipeline\n",
    "\n",
    "# Suppose:\n",
    "#  - cont_feats = ['age','income']\n",
    "#  - cat_feats  = ['city','education_level']\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"cont\", StandardScaler(),    cont_feats),\n",
    "    (\"cat\",  OneHotEncoder(drop=\"first\"), cat_feats),\n",
    "])\n",
    "\n",
    "model = make_pipeline(preprocessor,\n",
    "                      Ridge(alpha=best_alpha))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Why it works  \n",
    "1. **Numeric-only input**: Once encoded, every column is just a number, so Ridge applies its usual \\(\\ell_2\\) penalty.  \n",
    "2. **Shared shrinkage**: If your original categorical had many dummies, Ridge will softly shrink all their coefficients together rather than zeroing some out entirely.  \n",
    "\n",
    "---\n",
    "\n",
    "### Takeaway  \n",
    "As long as you **encode** your categorical variables into numeric form (and **scale** everything), Ridge Regression can seamlessly handle mixed data types. If you need hard feature selection on those dummies, consider wrapping Ridge inside an RFE or using an \\(\\ell_1\\)‑based method on the encoded features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef8d109-964b-4622-9235-51b29eac241b",
   "metadata": {},
   "source": [
    "#### Q7. How do you interpret the coefficients of Ridge Regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c43c6ad-8b17-49a6-9611-507c244ae668",
   "metadata": {},
   "source": [
    "In Ridge regression, the fitted coefficients \\(\\hat\\beta_j\\) still carry the usual “effect‐size” interpretation—but with two important caveats due to the L₂ penalty:\n",
    "\n",
    "1. **Unit‐change interpretation (conditional on other features)**  \n",
    "   - Just like in OLS, \\(\\hat\\beta_j\\) represents the expected change in the response \\(y\\) for a one‑unit increase in \\(x_j\\), **holding all other predictors fixed**.  \n",
    "   - Sign indicates direction (positive means \\(y\\) goes up as \\(x_j\\) increases; negative means \\(y\\) goes down).\n",
    "\n",
    "2. **Shrinkage bias**  \n",
    "   - Because Ridge minimizes  \n",
    "     $$\n",
    "       \\sum_{i}(y_i - \\mathbf{x}_i^T\\beta)^2 \\;+\\;\\lambda\\sum_j\\beta_j^2,\n",
    "     $$ \n",
    "     each \\(\\hat\\beta_j\\) is “pulled” toward zero relative to its OLS estimate.  \n",
    "   - Thus the raw magnitude of \\(\\hat\\beta_j\\) is **smaller** than in an unpenalized model; you should **not** compare ridge‐coefficients directly to OLS‐coefficients.\n",
    "\n",
    "3. **Standardization matters**  \n",
    "   - If you standardize each feature to mean 0 and variance 1 **before** fitting, then the magnitudes \\(|\\hat\\beta_j|\\) become directly comparable: larger \\(|\\hat\\beta_j|\\) means that feature has a stronger relative impact on \\(y\\).  \n",
    "   - If you don’t standardize, differences in scale will be confounded with shrinkage (the penalty treats a coefficient on a “wide” feature the same as on a “narrow” feature).\n",
    "\n",
    "4. **No zero coefficients**  \n",
    "   - Unlike Lasso, Ridge never exactly zeroes a coefficient. So small—but nonzero—\\(\\hat\\beta_j\\) still indicate weaker predictors, but you’ll need to impose your own threshold if you want to drop features.\n",
    "\n",
    "5. **Statistical inference caution**  \n",
    "   - The L₂ penalty introduces bias, breaking the usual OLS sampling distributions.  \n",
    "   - If you need confidence intervals or p‑values, you can use bootstrapping or Bayesian interpretations (view Ridge as a Gaussian prior on \\(\\beta\\)), but you **cannot** plug \\(\\hat\\beta_j\\) straight into the OLS formula for standard errors.\n",
    "\n",
    "---\n",
    "\n",
    "### Practical tips\n",
    "\n",
    "- **Report standardized coefficients** when you want to discuss “which features matter most.”  \n",
    "- **Visualize** coefficients (e.g., bar plot) to see relative shrinkage across features.  \n",
    "- **Post‑hoc recalibration**: if interpretability is paramount, you can fit a final OLS on the subset of top features selected by Ridge (or RFE) to get unbiased estimates on those.  \n",
    "\n",
    "In short, Ridge coefficients still tell you *direction* and *relative importance*—but remember they’re biased by design, so adjust your interpretation accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102da17e-29da-4013-8d23-4d6bbd59e3d7",
   "metadata": {},
   "source": [
    "#### Q8. Can Ridge Regression be used for time-series data analysis? If yes, how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4d7b3-625c-4223-a41e-46bedbe7df9c",
   "metadata": {},
   "source": [
    "Yes—Ridge regression is perfectly usable for time‑series problems, provided you first turn your series into a supervised learning design matrix. The key steps are:\n",
    "\n",
    "1. **Create lagged features**  \n",
    "   - For a univariate series \\(y_t\\), build predictors like  \n",
    "     $$\n",
    "       x_{t,1} = y_{t-1},\\; x_{t,2} = y_{t-2},\\;\\dots,\\;x_{t,p} = y_{t-p}.\n",
    "     $$\n",
    "   - You can also add rolling‑window statistics (means, variances), seasonal dummies (month or day‑of‑week one‑hots), and exogenous regressors.\n",
    "\n",
    "2. **Train/test split preserving time order**  \n",
    "   - Use a **chronological split** (e.g. train on \\(t=1\\ldots T_0\\), validate on \\(T_0+1\\ldots T_1\\), test on \\(T_1+1\\ldots T\\)) or time‑series cross‑validation (e.g. expanding windows) rather than random shuffling.\n",
    "\n",
    "3. **Standardize your features**  \n",
    "   - Since Ridge’s L₂ penalty treats every coefficient equally, scale each lagged series (and dummy) to zero mean/unit variance before fitting.\n",
    "\n",
    "4. **Fit Ridge on the lagged design matrix**  \n",
    "   ```python\n",
    "   from sklearn.linear_model import Ridge\n",
    "   from sklearn.preprocessing import StandardScaler\n",
    "   from sklearn.pipeline import make_pipeline\n",
    "\n",
    "   model = make_pipeline(\n",
    "       StandardScaler(),\n",
    "       Ridge(alpha=best_alpha)\n",
    "   )\n",
    "   model.fit(X_lagged_train, y_train)\n",
    "   y_pred = model.predict(X_lagged_test)\n",
    "   ```\n",
    "\n",
    "5. **Hyperparameter tuning via time‑series CV**  \n",
    "   - Use walk‑forward or expanding‑window CV to pick the best \\(\\lambda\\) (alpha) so you respect temporal order.\n",
    "\n",
    "6. **Extensions**  \n",
    "   - **Vector autoregression (VAR)**: stack multiple series’ lags into one big design matrix, then apply a multivariate ridge penalty to stabilize coefficient estimates.  \n",
    "   - **Structured regularization**: you can penalize groups of lags (e.g. all seasonal dummy coefficients) more or less heavily by extending L₂ to block‑diagonal penalties.\n",
    "\n",
    "---\n",
    "\n",
    "### Why it helps in time‑series  \n",
    "- **Multicollinearity** is endemic in lagged features (adjacent lags correlate strongly). Ridge’s L₂ shrinkage stabilizes those highly collinear predictors.  \n",
    "- **Overfitting** on many lags or external regressors is tamed, improving out‑of‑sample forecast accuracy.  \n",
    "\n",
    "---\n",
    "\n",
    "**Bottom line:**  \n",
    "Treat your time series as regression data with lagged and calendar features, then regularize with Ridge to get more robust coefficient estimates and better forecasts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
